# resume-portfolio

# Trading Journal Data Pipeline

## Overview

A Python-based ETL pipeline to process and transform user trade data from Google Sheets, clean and aggregate the data, and load it into Snowflake for centralized storage and analysis. Orchestrated using Apache Airflow to automate and schedule the workflow.

## Features

- **Data Extraction:** Retrieves trade data from Google Sheets using Google Sheets API.
- **Data Cleaning:** Cleans and prepares data using Pandas.
- **Data Loading:** Loads transformed data into Snowflake.
- **Orchestration:** Automates the ETL process with Apache Airflow.
- **Visualization:** Generates reports and visualizations using Plotly and Matplotlib.

## Technologies Used

- **Programming Languages:** Python, SQL
- **ETL Tools:** Pandas, SQLAlchemy
- **Workflow Orchestration:** Apache Airflow
- **Databases:** Snowflake, PostgreSQL, MySQL
- **Data Visualization:** Plotly, Matplotlib
- **Others:** Git, GitHub, Linux

## Setup Instructions

1. **Clone the Repository:**
   ```bash
   git clone https://github.com/romsamo/resume-portfolio.git
   cd resume-portfolio/Trading_Journal_Data_Pipeline
